# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# streamlit_app.py  â€“Â Pages Â«â€¯Mise Ã Â jourâ€¯M2â€¯Â» (PC & Appairage)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
"""Deux workflowsÂ :
1. **PCÂ : Mise Ã Â jour des codesÂ M2** (2â€¯fichiers Nâ€‘1 + N) â†’ `M2_MisAJour_YYMMDD.csv`
2. **ClientÂ : Appairage M2â€¯â‡†â€¯famille** (Nâ€‘1 + N + mapping) â†’ `appairage_M2_CodeFamilleClient_YYMMDD.csv`
Les uploads persistent en session jusquâ€™au Â«â€¯Rerun & clearÂ Â» manuel.

`psutil` est optionnelÂ : ajouteâ€‘le dans *requirements.txt* si tu veux la jauge
mÃ©moire, sinon elle sâ€™affiche Â«â€¯n/aâ€¯Â».
"""
from __future__ import annotations
import csv, io, os
from datetime import datetime
from pathlib import Path
from typing import List, Dict

import pandas as pd
import streamlit as st

try:
    import psutil
except ModuleNotFoundError:
    psutil = None  # on masque juste la RAM

DEBUG_SAMPLE: int | None = None  # mettre 10_000 pour tester vite

st.set_page_config("Appairage / Mise Ã Â jour M2", "ğŸ› ï¸", layout="wide")
page = st.sidebar.radio("Navigation", ["Mise Ã Â jour M2 â€“ PC", "Mise Ã Â jour M2 â€“ Appairage client"], key="nav")

# â•â•â•â•â•â•â•â•â•â•â•â•â•  FONCTIONS UTILITAIRES  â•â•â•â•â•â•â•â•â•â•â•â•â•

def _read_csv(buf: io.BytesIO) -> pd.DataFrame:
    for enc in ("utf-8", "latin1", "cp1252"):
        buf.seek(0)
        try:
            sample = buf.read(2048).decode(enc, errors="ignore")
            sep = csv.Sniffer().sniff(sample, delimiters=";,|\t").delimiter
            buf.seek(0)
            return pd.read_csv(buf, sep=sep, encoding=enc, dtype=str, low_memory=True, on_bad_lines="skip")
        except (UnicodeDecodeError, csv.Error, pd.errors.ParserError):
            continue
    raise ValueError("CSV illisibleÂ : encodage/sÃ©parateur introuvable")

@st.cache_data(show_spinner=False, hash_funcs={io.BytesIO: lambda _: None})
def load_df(up) -> pd.DataFrame:
    ext = Path(up.name.lower()).suffix
    buf = io.BytesIO(up.getvalue())
    if ext == ".csv":
        return _read_csv(buf)
    if ext == ".xlsx":
        buf.seek(0)
        return pd.read_excel(buf, engine="openpyxl", dtype=str)
    raise ValueError(f"Extension {ext} non supportÃ©e")


def to_m2(s: pd.Series) -> pd.Series:
    return s.astype(str).str.zfill(6)


def add_cols(df: pd.DataFrame, ref_i: int, m2_i: int, ref_label: str, m2_label: str) -> pd.DataFrame:
    out = df.iloc[:, [ref_i-1, m2_i-1]].copy()
    out.columns = [ref_label, m2_label]
    out[m2_label] = to_m2(out[m2_label])
    return out


def ram() -> str:
    if psutil is None:
        return "n/a"
    return f"{psutil.Process(os.getpid()).memory_info().rss/1_048_576:,.0f}Â Mo"

# â•â•â•â•â•â•â•â•â•â•â•â•â•  COMPOSANT UPLOADER  â•â•â•â•â•â•â•â•â•â•â•â•â•

def uploader(prefix: str, lots: Dict[str, tuple[str, str, str]]):
    for k in lots:
        st.session_state.setdefault(f"{prefix}_{k}_files", [])
        st.session_state.setdefault(f"{prefix}_{k}_names", [])

    cols = st.columns(len(lots))
    for (k, (title, lab_ref, lab_val)), col in zip(lots.items(), cols):
        with col:
            st.subheader(title)
            ups = st.file_uploader("DÃ©poserâ€¦", type=("csv", "xlsx"), accept_multiple_files=True, key=f"uploader_{prefix}_{k}")
            if ups:
                new = 0
                for up in ups:
                    if up.name not in st.session_state[f"{prefix}_{k}_names"]:
                        st.session_state[f"{prefix}_{k}_files"].append(up)
                        st.session_state[f"{prefix}_{k}_names"].append(up.name)
                        new += 1
                if new:
                    st.success(f"{new} fichier(s) ajoutÃ©(s)")

            st.number_input(lab_ref, 1, 50, 1, key=f"{prefix}_{k}_ref")
            st.number_input(lab_val, 1, 50, 2, key=f"{prefix}_{k}_val")
            st.caption(f"{len(st.session_state[f'{prefix}_{k}_files'])} fichier(s) | RAMÂ : {ram()}")

# â•â•â•â•â•â•â•â•â•â•â•â•â•  PAGEÂ PC  â•â•â•â•â•â•â•â•â•â•â•â•â•
if page.startswith("Mise Ã Â jour M2 â€“ PC"):
    st.header("ğŸ”„Â Mise Ã Â jour des codesÂ M2Â (PersonalÂ Catalogue)")

    LOTS_PC = {
        "old": ("DonnÃ©esÂ Nâ€‘1", "RÃ©f. produit", "M2 ancien"),
        "new": ("DonnÃ©esÂ N",   "RÃ©f. produit", "M2 nouveau"),
    }
    uploader("pc", LOTS_PC)

    if st.button("ğŸš€Â GÃ©nÃ©rer le fichier M2_MisAJour", key="run_pc"):
        if not all(st.session_state[f"pc_{k}_files"] for k in LOTS_PC):
            st.warning("Merci de charger Nâ€‘1 et N.")
            st.stop()

        dfs = {}
        for k in LOTS_PC:
            parts = [load_df(f) for f in st.session_state[f"pc_{k}_files"]]
            if any(p is None for p in parts):
                st.error("Erreur de lecture.")
                st.stop()
            df = pd.concat(parts, ignore_index=True).drop_duplicates()
            if DEBUG_SAMPLE:
                df = df.head(DEBUG_SAMPLE)
            dfs[k] = df

        for k, df in dfs.items():
            r_i, m_i = st.session_state[f"pc_{k}_ref"], st.session_state[f"pc_{k}_val"]
            if not (1 <= r_i <= df.shape[1] and 1 <= m_i <= df.shape[1]):
                st.error(f"Indices hors plage ({k}).")
                st.stop()

        old_df = add_cols(dfs["old"], st.session_state["pc_old_ref"], st.session_state["pc_old_val"], "Ref", "M2_ancien")
        new_df = add_cols(dfs["new"], st.session_state["pc_new_ref"], st.session_state["pc_new_val"], "Ref", "M2_nouveau")

        merged = new_df.merge(old_df[["Ref", "M2_ancien"]], on="Ref", how="left")
        maj = merged.groupby("M2_nouveau")["M2_ancien"].agg(lambda s: s.value_counts().idxmax() if s.notna().any() else pd.NA).reset_index()

        dstr = datetime.today().strftime("%y%m%d")
        st.download_button("â¬‡ï¸Â TÃ©lÃ©charger M2_MisAJour.csv", maj.to_csv(index=False, sep=";"), file_name=f"M2_MisAJour_{dstr}.csv", mime="text/csv")
        st.success("Fichier gÃ©nÃ©rÃ©.")
        st.dataframe(maj.head())

# â•â•â•â•â•â•â•â•â•â•â•â•â•  PAGEÂ Appairage  â•â•â•â•â•â•â•â•â•â•â•â•â•
if page.startswith("Mise Ã Â jour M2 â€“ Appairage"):
    st.header("ğŸ”—Â Appairage M2 / famille client")

    LOTS_CL = {
        "old": ("DonnÃ©esÂ Nâ€‘1",   "RÃ©f. produit", "M2 ancien"),
        "new": ("DonnÃ©esÂ N",     "RÃ©f. produit", "M2 nouveau"),
        "map": ("Table mapping", "M2 ancien",   "Code famille client"),
    }
    uploader("cl", LOTS_CL)

    if st.button("ğŸš€Â GÃ©nÃ©rer l'appairage", key="run_cl"):
        if not all(st.session_state[f"cl_{k}_files"] for k in LOTS_CL):
            st.warning("Merci de charger les 3 fichiers.")
            st.stop()

        dfs = {}
        for k in LOTS_CL:
            parts = [load_df(f) for f in st.session_state[f"cl_{k}_files"]]
            if any(p is None
